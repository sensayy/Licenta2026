# Malware Classification Diploma Project

This repository contains the source code and data for a **finalâ€‘year diploma project** in the field of malware analysis and machine learning. The goal is to explore different approaches for **classifying malware families** based on fileâ€‘level features extracted from a public dataset (`train.7z`) and to compare classical ML models with a simple convolutional neural network.

---

## ğŸ” What the Project Does

- **Parses raw malware files** (`.bytes`) to remove address information.
- **Extracts byteâ€‘frequency features**, file sizes and labels into CSVs.
- **Converts byte streams to grayscale images** for CNN training.
- **Trains and evaluates**:
  - Random Forest
  - XGBoost (with optional hyperâ€‘parameter tuning)
  - A lightweight PyTorch CNN
- **Generates visualisations** to understand dataset distribution and model behaviour.
- Includes utility scripts for dataset inspection and preprocessing.

---

## ğŸ—‚ï¸ How the Files Work Together

| Script / File | Purpose |
|---------------|---------|
| `HexCount.py` | Remove memoryâ€‘address column from `.bytes` files. |
| `bytescsv.py` | Count hexâ€‘byte occurrences and merge with sizes/labels. |
| `filesize.py` / `filesize_graph.py` | Extract and visualise file sizes. |
| `data_graph.py` | Plot class distribution (count & pie). |
| `hex_img.py` | Generate 256â€‘pixelâ€‘wide grayscale images from parsed bytes. |
| `img_rename.py`, `test.py` | Helpers for cleaning/validating images & labels. |
| `Initial_Training.py` | Baseline models + featureâ€‘importance plots. |
| `HyperParameterXG.py` | Randomised search for XGBoost hyperâ€‘parameters. |
| `Image_Training.py` | Train CNN on image representations. |
| `CNN_Report.py` | Load saved CNN, compute classification report & confusion matrix. |

Data files such as `trainLabels.csv`, `labels_sizes.csv`, and `ByteCount_Size_Labels.csv` are either provided or generated by the preprocessing scripts. Processed data are stored in subfolders like `parsed_bytes/`, `images/` and `images_resized/`.

---

## ğŸ“Š Graphs & Visualisations

Several scripts produce charts used in analysis or the diploma report:

- **Class distribution** (`data_graph.py`): bar chart + pie chart showing how many samples per malware family.
- **File size analysis** (`filesize_graph.py`): min/mean/max of `.asm` and `.bytes` sizes per family (log scale).
- **Model diagnostics** (`Initial_Training.py`, `CNN_Report.py`): featureâ€‘importance bars, accuracy plots, confusion matrices.
- The generated figures are saved as PNGs in the repository root.

---

## âš™ï¸ Getting Started

1. **Clone the repository**  
   ```bash
   git clone <repo-url>
   cd Licenta
   ```

2. **Create and activate a Python virtual environment**  
   ```powershell
   python -m venv .venv
   .\.venv\Scripts\Activate.ps1   # Windows
   ```

3. **Install dependencies**  
   (no `requirements.txt` is provided, but the following packages are required)
   ```bash
   pip install pandas numpy matplotlib seaborn scikit-learn xgboost torch torchvision pillow tqdm py7zr cupy
   ```

4. **Prepare the dataset**  
   - Place `train.7z` in the project root.  
   - Run `filesize.py` to generate `filesizes.csv`.  
   - Extract `.bytes` files to `./train` and run `HexCount.py` â†’ output in `parsed_bytes/`.  
   - Convert parsed bytes to images with `hex_img.py` (creates `images/`).

5. **Generate feature CSV**  
   ```bash
   python bytescsv.py
   # produces ByteCount_Size_Labels.csv
   ```

6. **Explore the data & train models**  
   ```bash
   python data_graph.py          # dataset visualisation
   python filesize_graph.py      # size analysis
   python Initial_Training.py    # baseline ML models
   python HyperParameterXG.py    # tune XGBoost
   python Image_Training.py      # train CNN
   python CNN_Report.py          # evaluate CNN
   ```

7. **Inspect / debug**  
   Use `test.py` to verify that label IDs match image filenames or `organizer.py` to sort CSV columns.

> ğŸ” Many scripts save plots or CSVs; rerun them when you update the data.

---

## ğŸ› ï¸ Maintainers & Contributions

- **Maintainer:** _[Your Name]_  
- This repository was created for academic purposes; feel free to fork, experiment, and learn.
- Contributions are welcome via pull requests. If you add major functionality (e.g. new model, data pipeline), please update this README accordingly.

For formal contribution guidelines, see `CONTRIBUTING.md` (if added) or the project wiki.

---

## ğŸ“„ Other Notes

- This is **not** productionâ€‘grade code; it was written for experimentation and demonstration.
- No license file is includedâ€”add one if you plan to share the code publicly.
- Keep generated data (CSVs, images) under version control only if they are small; otherwise use `backup/` to store intermediate artifacts.

> ğŸ’¡ **Tip:** Work incrementallyâ€”run preprocessing scripts once, then focus on model training and analysis. The notebooks/figures produced can be reused in your diploma report.

Good luck with your project!